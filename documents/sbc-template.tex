\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage{graphicx,url}

\usepackage[brazil]{babel}   
\usepackage[latin1]{inputenc}
\usepackage{hyperref}
\usepackage{booktabs}

\usepackage{color}
\usepackage{listings}

\lstset{ %
	language=C++,						% choose the language of the code
	basicstyle=\footnotesize,			% the size of the fonts that are used for the code
	numbers=left,						% where to put the line-numbers
	numberstyle=\footnotesize,		% the size of the fonts that are used for the line-numbers
	stepnumber=1,						% the step between two line-numbers. If it is 1 each line will be numbered
	numbersep=5pt,						% how far the line-numbers are from the code
	backgroundcolor=\color{white},	% choose the background color. You must add \usepackage{color}
	showspaces=false,					% show spaces adding particular underscores
	showstringspaces=false,			% underline spaces within strings
	showtabs=false,					% show tabs within strings adding particular underscores
	frame=single,						% adds a frame around the code
	tabsize=2,							% sets default tabsize to 2 spaces
	captionpos=b,						% sets the caption-position to bottom
	breaklines=true,					% sets automatic line breaking
	breakatwhitespace=false,			% sets if automatic breaks should only happen at whitespace
	escapeinside={\%*}{*)}				% if you want to add a comment within your code
}

\sloppy

\title{Workflow de desenvolvimento em C/C++ baseado em TDD. \\Pre-tested commits}

\author{Helton Luiz Marques\inst{1}} 

\address{Univali -- Universidade do Vale do Itajaí\\
		Pós--Graduação em Qualidade e Engenharia de Software\\
		Florianópolis -- SC -- Brasil
		\email{helton.marx@gmail.com}
}

\begin{document} 

\maketitle

\begin{abstract}
  This meta-paper describes the style to be used in articles and short papers
  for SBC conferences. For papers in English, you should add just an abstract
  while for the papers in Portuguese, we also ask for an abstract in
  Portuguese (``resumo''). In both cases, abstracts should not have more than
  10 lines and must be in the first page of the paper.
\end{abstract}
     
\begin{resumo} 
	A proposta deste trabalho é apresentar o conceito de Test Driven Development,  
	mostrar os benefícios que esta abordagem traz para os desenvolvedores, e 
	também apresentar a revisão de código para análise e busca de falhas no 
	código fonte, alterações na arquitetura do sistema, reimplementação de 
	funcionalidades já existentes, duplicidade de códigos e melhorias de 
	estética e padronização.
	São apresentados os benefícios da utilização dessas metodologias e 
	por fim um workflow de desenvolvimento em C/C++ baseado em TDD.
\end{resumo}


\section{Introdução}

Com a popularização dos métodos ágeis difundiu-se e muito o desenvolvimento
orientado a testes (\textit{Test Driven Development}), onde há uma busca 
constante em eliminar falhas de programação durante a codificação, com foco 
principalmente em design, pois produzir um código testável implica em baixo 
acoplamento, além do acréscimo de qualidade sobre o produto de software.\\
Além dos testes unitários, há também a revisão de código, que integrado a um 
sistema de testes automatizados e um sistema de controle de versão obtêm-se uma 
metodologia de trabalho eficaz e que traz velocidade e segurança no 
desenvolvimento de sistemas, principalmente em C/C++ onde há uma gama enorme 
de plataformas e arquiteturas para esta linguagem.\\
Este artigo apresentará uma proposta de workflow para desenvolvimento em C/C++ 
baseado em TDD, utilizando \textit{pre-tested commits}, sendo possível 
expandí-lo a outras linguagens de programação.

\newpage

\section {Fundamentação Teórica} \label{sec:theoreticalFoundation}

\textit{Test Driven Development} (TDD) é uma abordagem iterativa para 
desenvolvimento de software baseada em testes automatizados. 
A idéia é aplicar pequenos ciclos de teste-codificação-refatoração, 
também conhecido como \textit{red-green-refactor} que consiste em criar um 
teste unitário que faça falhar o código desenvolvido (\textit{Red}), 
alterar o código para que o teste passe da forma mais simples (\textit{Green}) 
e refatorar o código com o objetivo de melhorar a sua estrutura e design 
(\textit{Refactor}).
Este ciclo deve ser repetido em pequenos incrementos, até que a funcionalidade 
esteja pronta.\\Assim em cada iteração, a complexidade vai aumentado aos poucos, 
porém com a certeza que há corretude em cada implementação.\\
Cada passo traz um benefício. Escrever o teste antes, prática conhecida 
como \textit{Test First}, obrigatoriamente força com que o código produzido 
seja testável por construção, e código testável implica código com baixo 
acoplamento, aspecto extremamente importante no design de software.\\ 
Ao escrever testes previamente, faz com que o desenvolvedor pense 
antecipadamente no comportamento que a aplicação deve ter, antes mesmo de 
escrever algum código. Desde a implementação, o projeto terá um nível de 
qualidade mais apurado, já que esta técnica força pensar em problemas e 
suas soluções antes de qualquer código existir.\\
Além disso, tem-se o \textit{feedback} imediato a cada refatoração, 
e também a diminuição do \textit{over--engineering}, ou seja, 
implementar mais do que o estritamente necessário.
O feedback acontece a cada ciclo, dando uma margem 
de segurança ao desenvolvedor de o que está sendo implementado além de correto 
é necessário.\\
TDD pode ser aplicado tanto para pequenas partes que compõem um 
sistema (Teste Unitários) quanto para componentes (Testes de Integração), e 
traz benefícios tanto em design quanto em performance, pois depende da 
arquitetura de teste aplicada para garantir uma boa cobertura de testes, com 
um tempo relativamente menor na resolução de falhas do sistema total.\\
Além de diminuir o custo na fase de manutenção do sistema, oferece também uma 
margem de segurança maior aos desenvolvedores.\\
Os testes automatizados também podem funcionar como uma forma de documentação, 
pois estão descrevendo em partes o comportamento do sistema, suas interfaces, 
métodos e arquitetura.\\
TDD é entendido como um dos princípios da Extreme Programming (XP).\\
Os principais benefícios:
\begin{itemize}
	\item
		\textbf{Diminuição de falhas:} 
		Erros de lógica e também falhas de design podem 
		ser encontrados rapidamente durante o TDD, ocorrendo previamente a 
		prevenção de defeitos.
	\item
		\textbf{Menor tempo de debug:} 
		Com um menor número de falhas, obtêm-se um menor tempo de debug.
	\item
		\textbf{Documentação não mente:} 
		Com testes bem estruturados, é possível analisar a qualidade da 
		documentação. Testes bem estruturados trazem uma forma mais vísivel
		através de um exemplo funcional, suprindo uma documentação escassa.
	\item
		\textbf{Paz de espírito:} 
		Um código exaustivamente testado com um conjunto abrangente 
		de testes de unitários traz estabilidade e confiança aos desenvolvedores, 
		trazendo conforto e fins de semana despreocupados.
	\item
		\textbf{Aperfeiçoamento do design:} 
		Um bom design é um design testável. 
		Funções muito grandes, forte acoplamento e condicionais complexas 
		tornam o código mais complexo e menos testável. Os desenvolvedores 
		percebem previamente uma falha de design caso os testes não possam ser 
		implementados.
	\item
		\textbf{Monitorar o progresso:}
		Os testes trazem exatamente um retrato do que está funcionando e uma 
		porcentagem real do trabalho realizado.
	\item
		\textbf{Feedback imediato:}
		O TDD traz imediatamente uma gratificação aos desenvolvedores. 
		A cada codificação testada, há uma garantia de que o software 
		implementando está funcionando
\end{itemize}

\subsection{Test-First e Test-Last}	\label{sec:testFirstLast}

Há duas abordagens em relação aos teste unitários, 
que são o \textit{Test-First} que força que o código de teste seja produzido 
antes da implementação do algoritmo, e o \textit{Test-Last} que ao inverso, 
é a elaboração do teste unitário após a conclusão do algoritmo a ser testado.\\
\cite{erdogmus:05}, resolveram investigar, por meio de um experimento 
as diferenças entre as abordagens \textit{Test-First} e \textit{Test-Last}. 
O experimento consiste em dois grupos em meio acadêmico, cada qual usando umas 
das abordagens. As conclusões foram as seguintes: 
o grupo \textit{Test-First} acabou escrevendo 52\% mais testes do que o grupo 
\textit{Test-Last}, algo bastante significativo. 
Em termos de qualidade externa, pelo estudo, não houve diferença entre os dois 
métodos. Houveram sim, evidências de que a qualidade externa estaria mais 
relacionada ao números de testes escritos do que quando estes 
são escritos previamente.\\ 
Segundo os autores, apesar do método \textit{Test-First} por si só não 
aumentar a qualidade, este pareceu ter um efeito positivo sobre a 
produtividade dos desenvolvedores, 
possivelmente por causa dos seguintes fatores:

\begin{itemize}
	\item
		\textbf{Melhor compreensão do problema:}
		Especificar o teste antes força o desenvolvedor a refletir de maneira 
		mais profunda e completa sobre o problema a ser resolvido. 
		Criar cenários de testes antes ajuda a provar a robustez da solução 
		proposta.
	\item
		\textbf{Melhor foco na tarefa a ser feita:}
		Existe uma menor carga cognitiva sobre o desenvolvedor, 
		pois ele estará concentrado em resolver apenas uma pequena porção do 
		problema, somente o suficiente para atender o teste existente falhando.
	\item
		\textbf{Aprendizado mais rápido:}
		O desenvolvedor saberá mais rapidamente se a funcionalidade implementada
		está de acordo com o esperado. Além disso, existe um critério inequívoco 
		para saber quando o trecho de funcionalidade está realmente pronto.
	\item
		\textbf{Menos esforço de retrabalho:}
		Em uma abordagem \textit{Test-Last}, corre-se o risco de pouca 
		refatoração, desenvolvendo a funcionalidade por inteiro, incorrendo em 
		retrabalho à medida que os testes forem criados posteriormente e 
		apontarem outros problemas.
\end{itemize}

O estudo demonstra claramente uma qualidade maior ao utilizarmos 
\textit{Test-First}, porém deve-se levar em consideração diversos fatores ao 
selecionar um método, principalmente quando há uma equipe mais experiente que 
saiba gerar produtividade unindo os dois métodos. Além disso, o risco da 
abordagem \textit{Test-Last} está na perda do benefício da programação por 
iteração, ou seja, evoluir o software a partir do ponto de vista de como se 
espera que seja usado, e também a ocorrência em demasia de 
\textit{over-engineering}, isto é, escrever código para coisas que talvez não 
sejam necessárias naquele momento. 

\subsection{Testes Automatizados}	\label{sec:automatedTests}

São uma ferramenta extremamente valiosa de feedback, 
ajudando a garantir tanto a qualidade externa (aquela perceptível pelo usuário), 
quanto à qualidade interna, aquela perceptível pelo desenvolvedor.\\
A facilidade de poder executar continuamente os testes permite a identificação 
imediata de alterações indesejáveis no sistema. Por essa razão, 
os testes existentes para um sistema também são conhecidos como 
\textit{Testes de Regressão}, pois asseguram que um sistema não irá regredir 
do ponto atual em que se encontra. 
O acréscimo contínuo de funcionalidades pode ser 
realizado sem medo de quebrar algo já estabilizado.\\
Os testes também favorecem a prática saudável de refatoração, que consiste em 
aplicar pequenas transformações na estrutura interna do software, preservando 
o comportamento externo, com o objetivo de melhorar o código, tornando-o mais 
legível e mais aderente às manutenções pelas quais deverá passar. 
Entretanto é necessário a busca pelo equilíbrio da refatoração, que deve ser 
disciplinada para manter a qualidade do código escrito.\\
Deve-se observar que o teste unitário é a base para os testes de integração, 
pois trazem um feedback imediato, encorajando o desenvolvedor a executá-los 
mais frequentemente, até a execução de todos os testes do sistema em um 
servidor de integração contínua.\\      
É vital que existam testes automatizados que sejam fáceis e rápidos de 
serem executados, pois caso contrário, os testes serão executados poucas vezes 
e os bugs serão descobertos de forma tardia no ciclo de desenvolvimento.

\subsection{Revisão de código fonte}	\label{sec:codeRevision}

O melhor período para se encontrar falhas em código fontes é durante a 
codificação.\\
Conforme relatado em \cite{jones:07}, inspeções de código formais são cerca de 
duas vezes tão eficiente quanto qualquer forma conhecida de testes para 
encontrar profundamente falhas sutis de programação, e são o único método 
conhecido que tem uma média acima de 80\% na eficiência de remoção de 
defeitos.\\
Infelizmente, há dificuldades em convencer desenvolvedores e gestores sobre 
tais vantagens. Gestores preocupam-se sobre a demanta de tempo utilizada para 
esta atividade e com conflitos com o cronograma do projeto, sem claro observar
mais atentamente ao ganho obtido pela busca não tardia de falhas de programação, 
por outro lado, desenvolvedores sentem-se desconfortáveis com revisões de código, 
principalmente por atingir seus egos e demonstrar suas falhas. 
Aliado a testes unitários concisos e a rigorosas sessões de revisão de código, 
é possível concluir uma tarefa livre de falhas antecipamente a inclusão dela no 
sistema de controle de versão.\\
Conforme \cite{subramaniam:06} Há alguns métodos utilizados para revisão de 
código, citados abaixo:
\begin{itemize}
	\item
		\textbf{Revisão Tardia:}
		É realizado um evento em que será realizado uma sessão de revisão de 
		código por todas as equipes da empresa, o que demonstra não ser a forma 
		mais eficaz de realizar as revisões de código, porque  
		grandes equipes de avaliação tendem a entrar em longas discussões e 
		uma revisão muito ampla não só pode ser desnecessário, 
		mas pode até ser prejudicial para o progresso do projeto.
	\item
		\textbf{Jogo Pick-up:}
		Assim que algum código é escrito, compilado, testado e pronto 
		para o \textit{commit}, o código é capturado para análise por outro 
		desenvolvedor. As revisão de \textit{pre-commit} são designados para 
		serem rápidos e sem extensas discussões, o que garante um código
		aceitável. Para eliminar quaisquer rotinas comportamentais ou vícios, o 
		ideal é que a revisão seja realizada por desenvolvedores distintos a 
		cada semana, através de um rodízio.
	\item
		\textbf{Programação em Par:}
		Utilizar a programação sempre em duplas, onde um desenvolvedor o 
		conduz a programação, utlizando o teclado e um outro desenvolvedor 
		senta-se ao lado e atua como navegador, indicando melhorias e falhas.
		De vez em quando, alternam-se os papéis.
		Com isso, há um aumento de atenção e crítica sobre o desenvolvimento 
		de uma funcionalidade.
		O ideal é integração entre desenvolvedores mais experientes, 
		com menos os experientes, para um aprendizado mútuo.
\end{itemize}

Outra técnica útil é utilizar um checklist para a revisão de código, por exemplo:
\begin{itemize}
	\item 
		É possível ler e compreender o código? 
	\item 
		Há alguma possível falha?
	\item 
		Será que o código tem qualquer efeito indesejável em outras partes 
		da aplicação? 
	\item 
		Existe alguma duplicação de código?
	\item 
		É possível aplicar melhorias ou refatoração para melhorar o código?
\end{itemize}

Além disso, é possível utilizar ferramentas de análise de código, como por 
exemplo, o \cite{website:gerrit}, que integradas ao sistema de 
controle de versão executam revisões em grupo do tipo
\textit{post-commit}, isto é, o código recém enviado ao repositório sofre uma 
análise de um grupo de desenvolvedores, que aprovam ou não o código indicando 
melhorias e alterações.

\subsection{Pre-Tested Commits}	\label{sec:preTestedCommits}

A proposta do \textit{pre-tested commit}, é dedicar um 
repositório primário ou um \textit{branch} dedicado ao servidor de 
integração contínua para que execute os testes unitários e de integração, 
antes de ir para o repositório principal ou \textit{branch} principal.\\
Isto é necessário porque há a possibilidade de desenvolvedores não executarem 
testes unitários ou funcionais após a conclusão de uma tarefa, 
enviando para o repositório uma possível falha.
Este tipo de ação pode ser justificada para um sistema muito complexo, com 
\textit{n} testes de integração, e que demandam muito tempo, até horas para 
completar todo o processo de testes.\\
Obviamente. é mandatório que o desenvolvedor execute seus testes unitários, 
mas há também, uma possibilidade que seus testes não cubram uma falha gerada 
acidentalmente em outra parte do sistema. 
Portanto, para que não ocorra quebra do repositório principal o 
\textit{pre-tested commit} é utilizado.\\
A utilização dele está fortemente ligado ao sistema de controle de versão, 
como o \cite{website:teamcity} ou a um conjunto 
de ferramentas configuradas para tal função, como por exemplo a utilização do 
\cite{website:git}(SCV), 
\cite{website:jenkins}(Integração Contínua), 
\cite{website:gtest}(Testes unitários) e o 
\cite{website:gerrit}(Revisão de Código).\\

\newpage

\section{Workflow}	\label{sec:workflow}

\begin{figure}[!htb]
	\centering
	\includegraphics[width=1.0\textwidth]{../processos/workflow.png}
	\caption{Workflow}
	\label{fig:workflow}
\end{figure}

O \textit{workflow} apresentado na Figura~\ref{fig:workflow} demonstra a 
integração entre o TDD e a utilização de \textit{pre-tested commits}, que pode
ser configurado em um repositório separado, ou conforme a política de versionamento
adotado, através de um \textit{branch} dedicado a availação e testes unitários e 
de integração, para trazer uma garantia do funcionamento pleno das tarefas 
implementadas, sem gerar também impacto no repositório principal.\\

\begin{figure}[!htb]
	\centering
	\includegraphics[width=1.0\textwidth]{../processos/TDD.png}
	\caption{Workflow TDD}
	\label{fig:TDD}
\end{figure}

Na Figura~\ref{fig:TDD} encontra-se o teste no ambiente local do 
desenvolvedor, que é responsável por implementar os testes unitários, 
executá-los, além de efetuar os testes funcionais para validação da tarefa.\\
Uma metodologia sugerida, é criar um branch local para a resolução de falhas, 
ou implementação de uma nova tarefa, aproveitando a excelente capacidade do 
merge do sistema de controle de versão Git. Segue o procedimento:

\begin{enumerate}
	\item 
		Clone do repositório principal: \texttt{git clone "repositório"}
	\item
		Criar um branch para executar as alterações: 
		\texttt{git branch -d "funcionalidadeX"}.
 	\item
		Realizar as alterações, executar os testes unitários localmente, e 
		realizar commits: \texttt{git commit -a}.
 	\item
		Retornar ao repositório anterior: 
		\texttt{git checkout "repositório"}.
 	\item
		Atualizar o repositório: \texttt{git pull}.
	\item
		Merge entre o repositório principal e o branch "funcionalidadeX": 
		\texttt{git merge "funcionalidadeX"}.
	\item
		Resolução de conflitos e execução dos testes unitários.
	\item
		Enviar o código ao repositório: \texttt{git push origin}.
\end{enumerate}

Já na Figura~\ref{fig:codeRevision} apresenta-se o workflow utilizado para 
a execução dos testes integrados utiizando o Jenkins, e na próxima ação a 
revisão de código pelos outros desenvolvedores utilizando o Gerrit.
Após a votação, modificações caso necessário, e a aprovacão o código é enviado
ao repositório ou \textit{branch} principal.\\
Consequentemente após este ciclo, há um código muito mais estável e seguro 
aplicado ao repositório principal.

\begin{figure}[!htb]
	\centering
	\includegraphics[width=1.0\textwidth]{../processos/codeRevision.png}
	\caption{Workflow Revisão de Código}
	\label{fig:codeRevision}
\end{figure}
	
\section{Avaliação}		\label{sec:evaluation}

Escolhemos como referência para este trabalho demonstrar a utilização do 
framework criado pelo Google para Testes Unitários para C/C++, o Google Test.
Este framework é utilizado pela própria equipe do Google para testes unitários 
em seus projetos em C/C++.\\
Alguns relatados na página do projeto são:
\begin{itemize}
	\item Chromium: \url{http://www.chromium.org}
	\item LLVM compiler: \url{http://llvm.org}
	\item Protocol Buffers: \url{http://code.google.com/p/protobuf/}
\end{itemize}

Baseado na arquitetura xUnit, portável para diversas arquiteturas 
(Linux, Mac OS X, Windows, Cygwin, Windows CE, e Symbian), 
e as principais funcionalidades para execução de testes unitários são, 
\textit{assertions}, \textit{death tests},  
\textit{value- and type-parameterized tests} e 	
integração com o Jenkins para teste contínuo através de um XML. 
Uma outra característica muito interessante deste framework é que foi 
projetado para ser leve (\textit{lightweight}) e com alta performance.\\
Em relação aos \textit{asserts} a diferença básica entre eles é que no
\verb!ASSERT_*! o teste é abortado ao encontrar uma diferença, e no \verb!EXPECT_*! 
o teste continua, mas demonstra uma falha no relatório de testes.
Alguns principais testes são baseados testes binários e testes de strings.\\

\subsection{Caso de Uso}	\label{sec:useCase}

Como caso de uso partimos para um exemplo simples de integração do 
Google Test(C++) com um projeto em C. A grande vantagem deste framework é a 
flexibilidade da linguagem atender as duas arquiteturas (C e C++), 
e sendo possível utilizá-la em projetos de pequeno e grande porte, 
e também atendendo aos desenvolvedores de sistemas embarcados.
Outra ferramenta utilizada no projeto é o make que é utilitário 
para verificar quais arquivos precisam ser compilados, além de automatizar o 
link de alguns diretórios, por exemplo, o diretório de arquivos de header (*.h).\\
O projeto tem a seguinte estrutura de diretórios:
\begin{itemize}
	\item \textit{include}: 
		diretório com arquivos de header (*.h)
	\item \textit{cadastro.h}: 
		arquivo contendo os protótipos das funções do arquivo cadastro.c.
	\item \textit{src}: 
		diretório com arquivos de código fonte (*.c).
	\item \textit{cadastro.c}: 
		arquivo com as funções de cadastro.
	\item \textit{main.c}: 
		arquivo principal, obrigatório para projetos em C.
	\item \textit{test}: 
		diretório com arquivos com código de testes cpp.
	\item \textit{cadastroTest.cpp}: 
		arquivo com os testes das funções do arquivo cadastro.c.
	\item \textit{main.cpp}: 
		arquivo principal, obrigatório para utilização do Google Test.
	\item \textit{Makefile}: 
		responsável pela compilação dos arquivos de testes.
	\item \textit{Makefile}: 
		arquivo responsável por executar a compilação dos 
		arquivos fontes, e arquivos de testes.
\end{itemize}

Para este exemplo, temos a seguinte regra:\\

\begin{center}
	\begin{tabular}{ | p{13cm} | }
		\hline
			Valor do Imóvel \\
		\hline
  			O itaú realizado o financiamento de imóveis residenciais a partir 
			de \verb!R$ 62 mil!, sem limite máximo.
			Foi criado um pequeno algoritmo que recebe o valor do financiamento, no 
			formato de string, verificar se a string é válida (diferente de vazio), 
			aplicando uma expressão regular para facilitar a validação da string, e 
			verificar se o valor encontra-se acima de \verb!R$62 mil! 
			(\verb!VALOR_IMOVEL_MIN!), 
			retornando o valor já no formato float em caso de sucesso, 
			ou o valor negativo  em caso de erro.\\
		\hline
	\end{tabular}
\end{center}

A partir da regra, temos a algoritmo do arquivo \textit{cadastro.c}:

\newpage

\begin{lstlisting}
#include <string.h>
#include <regex.h>

#include "cadastro.h"

#if (DEBUG >= 1)
#define DEBUG_MESSAGE(fmt, args...)		(fprintf(stderr, fmt, ##args))
#else
#define DEBUG_MESSAGE(fmt, args...)
#endif	/* (DEBUG >= 1) */

int check_regex(const char *er, const char *txt)
{
	regex_t regex;
	int ret;

	/** verify string to verify */
	if (!txt || !strlen(txt)) {
		return -1;
	}

	/** verify regular expression */
	if (!er || !strlen(er)) {
		return -1;
	}

	regcomp(&regex, er, REG_EXTENDED|REG_NOSUB);
	ret = regexec(&regex, txt,  0, NULL, 0);
	regfree(&regex);

	return ((ret != 0) ? -1 : 0);
}

float get_valor_imovel(const char * valor_imovel)
{
	float temp;
	/* expressão regular para convesão de strings para float */
	const char float_er[] = "[1-9][0-9]*\\.?[0-9]*([Ee][+-]?[0-9]+)?";

	if (check_regex(float_er, valor_imovel) != 0) {
		DEBUG_MESSAGE("\t\tvalor imóvel inválido %s\n", valor_imovel);
		return -1;
	}

	temp = atof(valor_imovel);
	if (temp < VALOR_IMOVEL_MIN) {
		DEBUG_MESSAGE("\t\tvalor do imóvel (%0.2f) abaixo do valor mínimo\n", temp);
		return -2;
	}
	return temp;
}
\end{lstlisting}

\newpage

Os testes aplicados sobre as funções contidas no arquivo cadastro.c, são colocados em um arquivo com o mesmo nome, com a extensão \_test.cpp, esta convenção serve para uma melhor visualização dos arquivos de testes unitários.\\
Há duas funções de testes gerais, e dentro de cada uma há execução de diversos testes.
É obrigatório a inclusão do header \verb!<gtest/gtest.h>!.
A função \verb!EXPECT_FLOAT_EQ! verifica o retorno da função \verb!get_valor_imovel!, 
igual a  \verb!R$ 65 mil!, conforme demonstrado no algoritmo abaixo:

\begin{lstlisting}
#include <gtest/gtest.h>

#include "cadastro.h"

TEST(cadastroTest, cadastroCheckRegexTest)
{
	const char float_er[] = "[1-9][0-9]*\\.?[0-9]*([Ee][+-]?[0-9]+)?";

	EXPECT_EQ(0, check_regex(float_er, "65000.00"));
	EXPECT_EQ(-1, check_regex(NULL, NULL));
}

TEST(cadastroTest, cadastroValorImovelTest)
{
	EXPECT_EQ(-1, get_valor_imovel(NULL));
	EXPECT_EQ(-2, get_valor_imovel("6300.00"));

	EXPECT_FLOAT_EQ(65000.00, get_valor_imovel("65000.00"));
}
\end{lstlisting}

O projeto contem 2 arquivos de makefile, um arquivo encontra-se dentro do diretório test, e é executado para compilar os arquivos de testes.O arquivo Makefile na raiz do projeto compila o projeto (make all), e chama o arquivo Makefile contido no diretório de testes (make test).\\
Uma observação, quando citamos 'compilar' pelo arquivo Makefile, na verdade, o script make é responsável por chamar o compilador repassando de forma correta os parâmetros, automatizando a tarefa de compilação.\\
\newpage

Abaixo o arquivo de compilação do diretório de Test.

\begin{lstlisting}
CPP=g++

ALL_C	:= $(wildcard ../src/*.c)
ALL_CPP	:= $(wildcard *.cpp)

SOURCES	:= $(filter-out %main.c,$(ALL_C))
OBJS	:= $(addprefix , $(SOURCES:.c=.o))
OBJS	+= $(addprefix , $(ALL_CPP:.cpp=.o))

CFLAGS	+= -fprofile-arcs -ftest-coverage
CFLAGS  += -I../include 

LDFLAGS += -lgtest -lgcov -lpthread -lgtest_main

TARGET := json_test

#	make all
all: $(TARGET)
        
$(TARGET): $(OBJS)
	@echo "[BIN] $@"
	@$(CPP) $^ $(LDFLAGS) -o $@
	@./$(TARGET)

%.o: %.c
	@echo "[CPP] $@"
	@$(CPP) $(CFLAGS) -o $@ -c $<
        
%.o: %.cpp
	@echo "[CPP] $@"
	@$(CPP) $(CFLAGS) -o $@ -c $<

clean:
	@echo "rm -rf $(OBJS)"
\end{lstlisting}

\newpage

Ao executar os testes temos:

\begin{figure}[!htb]
	\centering
	\includegraphics[width=1.0\textwidth]{makeTest.png}
	\caption{Execução dos Testes Unitários}
	\label{fig:makeTest}
\end{figure}

\section{Conclus\~ao}	\label{sec:conclusion}

Neste trabalho apresentamos como funciona um ciclo de desenvolvimento utilizando TDD e como ele resulta em melhores resultados através de um melhor entendimento prévio do problema, avanço incremental do código criado, mais confiança no código escrito e uma melhoria no design projeto de software onde há a busca por um baixo acoplamento para facilitar o desenvolvimento dos testes unitários.\\

Para o uso do TDD são necessárias bibliotecas e ferramentas que possibilita a escrita dos testes e a sua execução. Neste trabalho apresentamos o Google Test, framework para as linguagens C e C++, que tem como vantagem ser leve, portável e gratuito. Detecta automaticamente os testes escritos, agilizando o desenvolvimento e evitando que sejam escritos testes que nunca serão executados. \\

Através de um exemplo prático, mostramos como adotar uma estratégia de desenvolvimento dirigida a testes e - principalmente - que este processo não precisa ser burocrático e demorado. Com uma ferramenta simples, como o Google Test, em poucos minutos qualquer desenvolvedor pode começar a escrever testes e, a partir deles, o código propriamente dito.\\

\newpage

\bibliographystyle{sbc}
\bibliography{sbc-template}

\end{document}
